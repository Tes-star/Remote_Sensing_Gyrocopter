{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from Modelling.Baselines.Data_Preprocessing import Import_Labeled_Data\n",
    "X,Y=Import_Labeled_Data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: 980\n",
      "X_test Shape: 420\n",
      "y_train Shape: 980\n",
      "y_test Shape:420\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, stratify=Y)\n",
    "\n",
    "print(f'X_train Shape: {len(X_train)}\\nX_test Shape: {len(X_test)}\\ny_train Shape: {len(y_train)}\\ny_test Shape:{len(y_test)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbor Classifier (K-NNC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.28571428571428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.87      0.75       192\n",
      "         1.0       0.70      0.65      0.68       117\n",
      "         3.0       0.69      0.38      0.49        29\n",
      "         6.0       0.90      0.53      0.67        68\n",
      "         7.0       0.20      0.07      0.11        14\n",
      "\n",
      "    accuracy                           0.69       420\n",
      "   macro avg       0.63      0.50      0.54       420\n",
      "weighted avg       0.70      0.69      0.68       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_pred) * 100}\")\n",
    "print(classification_report(y_test, knn_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-Nearest Neighbor Classifier (K-NNC) with Scaled Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.9047619047619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.91      0.78       192\n",
      "         1.0       0.73      0.63      0.68       117\n",
      "         3.0       0.64      0.31      0.42        29\n",
      "         6.0       0.93      0.62      0.74        68\n",
      "         7.0       0.50      0.21      0.30        14\n",
      "\n",
      "    accuracy                           0.72       420\n",
      "   macro avg       0.70      0.54      0.58       420\n",
      "weighted avg       0.73      0.72      0.71       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Modelling.Baselines.Data_Preprocessing import scale_data\n",
    "\n",
    "#Scale data\n",
    "X_train=scale_data(X_train)\n",
    "X_test=scale_data(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_pred) * 100}\")\n",
    "print(classification_report(y_test, knn_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Light BGM with Scaled Data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Label must be in [0, 4), but found 6 in label",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLightGBMError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[1;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 18>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m15\u001B[39m\n\u001B[0;32m     16\u001B[0m params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_class\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m  \u001B[38;5;66;03m#no.of unique values in the target class not inclusive of the end value\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m clf \u001B[38;5;241m=\u001B[39m \u001B[43mlgb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m lgb_predictions \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(lgb_predictions[\u001B[38;5;241m1\u001B[39m], np\u001B[38;5;241m.\u001B[39margmax(lgb_predictions[\u001B[38;5;241m1\u001B[39m]))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\earth-analytics-python\\lib\\site-packages\\lightgbm\\engine.py:271\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;66;03m# construct booster\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 271\u001B[0m     booster \u001B[38;5;241m=\u001B[39m \u001B[43mBooster\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_valid_contain_train:\n\u001B[0;32m    273\u001B[0m         booster\u001B[38;5;241m.\u001B[39mset_train_data_name(train_data_name)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\earth-analytics-python\\lib\\site-packages\\lightgbm\\basic.py:2610\u001B[0m, in \u001B[0;36mBooster.__init__\u001B[1;34m(self, params, train_set, model_file, model_str, silent)\u001B[0m\n\u001B[0;32m   2608\u001B[0m params_str \u001B[38;5;241m=\u001B[39m param_dict_to_str(params)\n\u001B[0;32m   2609\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mc_void_p()\n\u001B[1;32m-> 2610\u001B[0m \u001B[43m_safe_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLGBM_BoosterCreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2611\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mc_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_str\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2614\u001B[0m \u001B[38;5;66;03m# save reference to data\u001B[39;00m\n\u001B[0;32m   2615\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_set \u001B[38;5;241m=\u001B[39m train_set\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\earth-analytics-python\\lib\\site-packages\\lightgbm\\basic.py:125\u001B[0m, in \u001B[0;36m_safe_call\u001B[1;34m(ret)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;124;03m\"\"\"Check the return value from C API call.\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \n\u001B[0;32m    119\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;124;03m    The return value from C API calls.\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LightGBMError(_LIB\u001B[38;5;241m.\u001B[39mLGBM_GetLastError()\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "\u001B[1;31mLightGBMError\u001B[0m: Label must be in [0, 4), but found 6 in label"
     ]
    }
   ],
   "source": [
    "from numpy import unique\n",
    "\n",
    "unique(Y)\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.03\n",
    "params['boosting_type'] = 'gbdt'  #GradientBoostingDecisionTree\n",
    "params['objective'] = 'multiclass'  #Multi-class target feature\n",
    "params['metric'] = 'multi_logloss'  #metric for multi-class\n",
    "params['max_depth'] = 15\n",
    "params['num_class'] = 4  #no.of unique values in the target class not inclusive of the end value\n",
    "\n",
    "clf = lgb.train(params, d_train, 100)\n",
    "lgb_predictions = clf.predict(X_test)\n",
    "print(lgb_predictions[1], np.argmax(lgb_predictions[1]))\n",
    "# lbg_pred = [np.argmax(x) for x in lgb_predictions]\n",
    "# np.array(lbg_pred).shape\n",
    "\n",
    "lgb_pred = np.argmax(lgb_predictions, axis=1)\n",
    "lgb_pred.shape\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lgb_pred) * 100}\")\n",
    "print(classification_report(y_test, lgb_pred))\n",
    "# Visualize Classification Map of LightGBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}